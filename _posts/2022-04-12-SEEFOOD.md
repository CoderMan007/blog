---
layout: post
title: "SEEFOOD"
author_github: vinayakj02
date: 2022-04-12 15:00:00
image: '/assets/img/'
description: 'Recreating the SEE-FOOD app from Silicon Valley using Transfer Learning in PyTorch'
tags:
 - IEEE NITK
 - Blog
 - Deep Learning
 - PyTorch
 - Transfer Learning
 - CNNs
categories:
 - CompSoc 
github_username: 'vinayakj02'
---



![phone-gif](/blog/assets/img/SEEFOOD/gif1.gif) <br>
SEEFOOD is an application which basically predicts if an image is an image of a hot-dog or not. This is based on the model used in the [HBO's Silicon Valley ](https://www.youtube.com/watch?v=vIci3C4JkL0). <br>
![S-E-E FOOD](/blog/assets/img/SEEFOOD/gif2.gif) <br>

### How to start ? 
First, we need to get a dataset for training the model. For this, there is a [dataset on kaggle ](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog) which perfectly matches our needs. So now that we have a dataset, we need to build and train the actual model.  
 
### Let's start coding. 
The notebook is [here](https://github.com/vinayakj02/SEEFOOD-classifier/blob/master/seefood_notebook.ipynb) if you want to follow through as you're reading the article. 

First, off we import all the required libraries.
![image](/blog/assets/img/SEEFOOD/image1.png)

Before importing the dataset we can use a simple transform to ensure all our images and resized, center cropped, and convert into tensors. Now we can import both the test and validation sets. Since the number of images here is not very high we can use a batch size of 20.

![image](/blog/assets/img/SEEFOOD/image2.png)
Once the dataset is loaded we can view the images. 
 
### Building the model
Since we are dealing with images we would need to use a model which is based on Convolutional Neural Networks (CNNs). The model itself would be a binary classifier to detect whether the food item is a "hot dog" or not. Smaller models with lower layers do not tend to work because they are simply not powerful enough to detect the different features, so we can see a good use case of transfer learning here. 

For this purpose we can use the densenet121 model, you can read more about Densely Connected Convolutional Networks in this paper [here](https://arxiv.org/pdf/1608.06993.pdf).
![image](/blog/assets/img/SEEFOOD/image3.png). Since we are only going to train the last block of the model we can freeze all the other parameters of the model.  If we take a look at the classifier currently we can see it's a classifier that has 1024 input features and 1000 output features. 
We can redefine this classifier for our case here. 
![image](/blog/assets/img/SEEFOOD/image4.png)

### Training the model
For the loss function here we can use the negative log-likelihood loss. Since we are training only the classifier part of the model, we need to include only the parameters from that block in the optimizer.
![image](/blog/assets/img/SEEFOOD/image5.png)

If you are trying to train the model, do make use of GPUs on google colab or kaggle. This speeds up the training process a lot. 
![image](/blog/assets/img/SEEFOOD/image6.png)
![image](/blog/assets/img/SEEFOOD/image7.png)

### Result
On training it for about 6 epochs I got around 86% accuracy. 
![image](/blog/assets/img/SEEFOOD/image8.png).

### Interesting question ?
Why do you think densenet121 was used for this model ?

## Links and resources
- [Github repo containing all the code and model weights](https://github.com/vinayakj02/SEEFOOD-classifier)
- [Dataset on Kaggle](https://www.kaggle.com/datasets/dansbecker/hot-dog-not-hot-dog)
- [A practical example to learn Transfer learning with PyTorch](https://towardsdatascience.com/a-practical-example-in-transfer-learning-with-pytorch-846bb835f2db)
